{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb1c09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Helper function for 'axis equal' in matplotlib's 3d view \n",
    "def set_3d_axes_equal(ax):\n",
    "    x_limits = ax.get_xlim3d()\n",
    "    y_limits = ax.get_ylim3d()\n",
    "    z_limits = ax.get_zlim3d()\n",
    "    x_range = abs(x_limits[1] - x_limits[0])\n",
    "    x_middle = np.mean(x_limits)\n",
    "    y_range = abs(y_limits[1] - y_limits[0])\n",
    "    y_middle = np.mean(y_limits)\n",
    "    z_range = abs(z_limits[1] - z_limits[0])\n",
    "    z_middle = np.mean(z_limits)\n",
    "    plot_radius = 0.5*max([x_range, y_range, z_range])\n",
    "    ax.set_xlim3d([x_middle - plot_radius, x_middle + plot_radius])\n",
    "    ax.set_ylim3d([y_middle - plot_radius, y_middle + plot_radius])\n",
    "    ax.set_zlim3d([z_middle - plot_radius, z_middle + plot_radius])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9c37c9",
   "metadata": {},
   "source": [
    "# Problem definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88bd7f0",
   "metadata": {},
   "source": [
    "Applications:\n",
    "- Iterative closest point algorithm for point cloud registration\n",
    "- Robot navigation\n",
    "- Optimal transformation between two trajectories\n",
    "- [Comparing moluecular structures](https://cnx.org/contents/HV-RsdwL@23/Molecular-Distance-Measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560963bc",
   "metadata": {},
   "source": [
    "We wish to solve the following non-linear least squares problem:\n",
    "$$ \n",
    "\\min_{R,\\mathbf{t}} \\sum_{i=1}^{N} \\lVert(R\\mathbf{p}_i + \\mathbf{t}) - \\mathbf{q}_i\\lVert_2,\n",
    "$$\n",
    "where $R \\in SO(3)$ is the rotation matrix, $\\mathbf{t}\\in \\mathbb{R}^3$ is the translation vector and $\\mathbf{p}_i, \\mathbf{q}_i \\in \\mathbb{R}^3$ are the model and target points, respectively. With $\\mathbf{r}(R, \\mathbf{t}) = (R\\mathbf{p}_i + \\mathbf{t}) - \\mathbf{q}_i$ residual vector function, the problem can be written as:\n",
    "$$ \n",
    "\\min_{R,\\mathbf{t}} \\sum_{i=1}^{N} \\mathbf{r}(R,\\mathbf{t})^2,\n",
    "$$\n",
    "or in vector form:\n",
    "$$ \n",
    "\\min_{R,\\mathbf{t}} \\mathbf{r}^\\mathsf{T}(R,\\mathbf{t}) \\mathbf{r}(R,\\mathbf{t}).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d099274",
   "metadata": {},
   "source": [
    "To work with some data, we generate random points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdec074",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "pts_model = np.random.rand(10, 3) + np.array([1, 2, 3]) # so the point are not around the origin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0864947e",
   "metadata": {},
   "source": [
    "Then we need the ground truth rotation and translation values. I parametrize the rotation vector via Euler angles: $R(\\gamma, \\beta, \\alpha)$, where $\\gamma$ is the yaw, $\\beta$ is the pitch and $\\alpha$ is the roll angle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2d243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypr_gt = [45/180.0*math.pi, -15/180.0*math.pi, 20/180.0*math.pi]\n",
    "t_gt = [1, -2, 3]\n",
    "x_gt = np.append(ypr_gt, t_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e236abdb",
   "metadata": {},
   "source": [
    "The Euler angles are intrepreted as intrinsic rotations around the Z, Y and final the X axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08dce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_gt = Rotation.from_euler('ZYX', ypr_gt, degrees=False).as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2fbb13",
   "metadata": {},
   "source": [
    " Note that this is the same rotation as defining the extrinsic rotation in X, Y, Z axis order, but roll, pitch, yaw angle order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8c42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_int = Rotation.from_euler('ZYX', ypr_gt, degrees=False).as_matrix()\n",
    "R_ext = Rotation.from_euler('xyz', [ypr_gt[2], ypr_gt[1], ypr_gt[0]], degrees=False).as_matrix()\n",
    "np.linalg.norm(R_ext - R_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b3c32e",
   "metadata": {},
   "source": [
    "Finally we apply the rotation on our synthetic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c879618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_target = (R_gt @ pts_model.T).T + t_gt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7c161f",
   "metadata": {},
   "source": [
    "The random model points and the transformet target points look like this in 2D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03853cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(pts_model[:, 0], pts_model[:, 1])\n",
    "plt.scatter(pts_target[:, 0], pts_target[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39c96c4",
   "metadata": {},
   "source": [
    "... and in 3D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422bfe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_solution(pts_model, pts_target, pts_model_hat=None):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.scatter3D(pts_model[:,0], pts_model[:,1], pts_model[:,2], c='r', s=10)\n",
    "    ax.scatter3D(pts_target[:,0], pts_target[:,1], pts_target[:,2], c='b', s=10)\n",
    "    if pts_model_hat is not None:\n",
    "        ax.scatter3D(pts_model_hat[:,0], pts_model_hat[:,1], pts_model_hat[:,2], c='g', s=10)\n",
    "\n",
    "viz_solution(pts_model, pts_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b8eb0e",
   "metadata": {},
   "source": [
    "# Solution #1: Singular value decomposition ([Kabsch-Umeyama algorithm](https://en.wikipedia.org/wiki/Kabsch_algorithm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95592d65",
   "metadata": {},
   "source": [
    "In his 1978 paper, titled [\"A discussion of the solution for the best rotation to relate two sets of vectors\"](https://onlinelibrary.wiley.com/doi/abs/10.1107/S0567739478001680), Wolfgang Kabsch gave a closed form solution for the least squares estimate of the rotation, i.e. when $\\mathbf{t} = \\mathbf{0}$.  However obtaining the translation is somewhat trivial, Umeyama completes Kabsch algorithm in his 1991 paper titled [\"Least-squares estimation of transformation parameters between two point patterns\"](https://web.stanford.edu/class/cs273/refs/umeyama.pdf). For a more recent derivation, as it appears in modern computer vision courses, see the [lecture notes from ETH Zurich](https://igl.ethz.ch/projects/ARAP/svd_rot.pdf). Note that this is the standard way to solve the problem of finding the optimial transform between two sets of points in least squares sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf757b6e",
   "metadata": {},
   "source": [
    "SVD decomposition is the standard and most efficient way to find the rigid body transformation between two point sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec276349",
   "metadata": {},
   "source": [
    "First we need to compute the center of gravity (or the means) of the two point sets:\n",
    "$$\n",
    "\\bar{\\mathbf{p}} = \\frac{\\sum_{i=1}^N \\mathbf{p}_i}{N}, \n",
    "$$\n",
    "$$\n",
    "\\bar{\\mathbf{q}} = \\frac{\\sum_{i=1}^N \\mathbf{q}_i}{N},\n",
    "$$\n",
    "and then, move the point sets to their respective center of gravities:\n",
    "$$\n",
    "\\tilde{\\mathbf{p}} = \\mathbf{p} - \\bar{\\mathbf{p}},  \n",
    "$$\n",
    "$$\n",
    "\\tilde{\\mathbf{q}} = \\mathbf{q} - \\bar{\\mathbf{q}} .\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e672b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cog_model = np.mean(pts_model, axis=0)\n",
    "cog_target = np.mean(pts_target, axis=0)\n",
    "\n",
    "pts_model_cog = pts_model - cog_model\n",
    "pts_target_cog = pts_target - cog_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a63d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = pts_model_cog.T @ pts_target_cog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% SVD decomposition\n",
    "[U, S, V] = np.linalg.svd(C)\n",
    "V = V.T\n",
    "C_chk = U @ np.diag(S) @ V.T\n",
    "print('Check decomposition ( =0): ', np.linalg.norm(C_chk - C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08188039",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_svd = V @ U.T\n",
    "t_svd = cog_target - R_svd @ cog_model\n",
    "\n",
    "print('Check R ( =0): ', np.linalg.norm(R_svd - R_gt))\n",
    "print('Check t ( =0):', np.linalg.norm(t_svd - t_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d3b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_model_hat = (R_svd @ pts_model.T).T + t_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38125359",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_svd = np.linalg.norm(pts_model_hat - pts_target, axis=1)\n",
    "print('Check transformation ( =0)', np.linalg.norm(res_svd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8a134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_solution(pts_model, pts_target, pts_model_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8c755b",
   "metadata": {},
   "source": [
    "Computation time of SVD can be found here: https://www.cs.utexas.edu/users/inderjit/public_papers/HLA_SVD.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a6868e",
   "metadata": {},
   "source": [
    "# Solution with solving matrix inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce89818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import sqrtm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51ae4d4",
   "metadata": {},
   "source": [
    "We can also obtain the solution using following [formula](https://en.wikipedia.org/wiki/Kabsch_algorithm):\n",
    "$$\n",
    "R = (C^\\mathsf{T}C)^{1/2}C^{-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2671332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_minv = sqrtm(C.transpose() @ C) @ np.linalg.inv(C)\n",
    "print(np.linalg.norm(R_gt - R_minv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24591870",
   "metadata": {},
   "source": [
    "# Solution with derivative-free *scipy* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bcb6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290e70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_x =  lambda x0: Rotation.from_euler('ZYX', x0[:3], degrees=False).as_matrix()\n",
    "r_x = lambda x0: ((R_x(x0) @ pts_model.T).T + np.array([x0[3:6]]) - pts_target).ravel()\n",
    "print('Check residual function ( =0): ', np.linalg.norm(r_x(x_gt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f7e903",
   "metadata": {},
   "source": [
    "We will use the derivative free simplex method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76009a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([45.0-15.0, -15.0+25.0, 20.0+25.0, 1.0+1.5, -2.0+1.8, 3.0-1.2]) # converges to the solution in 914 iterations\n",
    "x0[:3] *= 1.0/180.0*math.pi\n",
    "#x0 = np.array([0, 0, 0, 0, 0, 0]) # converges to local minumum\n",
    "    \n",
    "res = minimize(lambda x: np.linalg.norm(r_x(x)), x0, method='nelder-mead',\n",
    "               options={'xatol': 1e-6, 'disp': True, 'maxiter': 2000})\n",
    "\n",
    "print('Check solution ( =0): ', np.linalg.norm(res.x - x_gt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289a1c96",
   "metadata": {},
   "source": [
    "As we can see this method is relatively sensitive to the choosen initial guess."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbade45e",
   "metadata": {},
   "source": [
    "However, we can find another derivative-free algorithm that provides the solution even with extreme initial guess. See the example with [BFGS](https://docs.scipy.org/doc/scipy/tutorial/optimize.html#broyden-fletcher-goldfarb-shanno-algorithm-method-bfgs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e98608",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([0, 0, 0, 0, 0, 0]) # converges to the solution in 49 iterations\n",
    "res = minimize(lambda x: np.linalg.norm(r_x(x)), x0, method='BFGS',\n",
    "               options={'disp': True, 'maxiter': 2000})\n",
    "\n",
    "print('Check solution ( =0): ', np.linalg.norm(res.x - x_gt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8219c",
   "metadata": {},
   "source": [
    "# Solution with Newton's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf2543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sym\n",
    "from math import cos, sin, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8876ecd7",
   "metadata": {},
   "source": [
    "In order to improve on the convergence rate and hopefully improve on the sensitivity of the initial guess, let's try to use analytical derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2ef57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "o, p, k, x, y, z = sym.symbols('o p k x y z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c74ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rx_s(theta):\n",
    "  return sym.Matrix([[ 1, 0           , 0           ],\n",
    "                   [ 0, sym.cos(theta),-sym.sin(theta)],\n",
    "                   [ 0, sym.sin(theta), sym.cos(theta)]])\n",
    "  \n",
    "def Ry_s(theta):\n",
    "  return sym.Matrix([[sym.cos(theta), 0, sym.sin(theta)],\n",
    "                   [ 0           , 1, 0           ],\n",
    "                   [-sym.sin(theta), 0, sym.cos(theta)]])\n",
    "  \n",
    "def Rz_s(theta):\n",
    "  return sym.Matrix([[sym.cos(theta), -sym.sin(theta), 0 ],\n",
    "                   [ sym.sin(theta), sym.cos(theta) , 0 ],\n",
    "                   [ 0           , 0            , 1 ]])\n",
    "\n",
    "ypr2rot_sym = lambda k, p, o: Rz_s(k) @ Ry_s(p) @ Rx_s(o)\n",
    "#print('Check rotation composition ( =0)', np.linalg.norm(R_fn(ypr_gt[0], ypr_gt[1], ypr_gt[2]) - R_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7c8ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_sym = ypr2rot_sym(k, p, o)\n",
    "R_sym_sub = R_sym.subs({k: float(ypr_gt[0]), p: float(ypr_gt[1]), o: float(ypr_gt[2])})\n",
    "R_sym_sub_np = np.array(R_sym_sub.tolist()).astype('float')\n",
    "print('Check rotation composition ( =0): ', np.linalg.norm(R_sym_sub_np - R_gt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac39b7f",
   "metadata": {},
   "source": [
    "Define cost function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f01775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_sym = np.tile(np.array([x, y, z]), (pts_model.shape[0], 1))\n",
    "res_sym_vec = (R_sym @ pts_model.T).T + dt_sym - pts_target\n",
    "res_sym_vec = res_sym_vec.reshape(pts_model.shape[0]*3, 1) # reshape it from (N x 3) -> (M x 1)\n",
    "cost_fn_sym = res_sym_vec.T @ res_sym_vec\n",
    "\n",
    "print('Number of chars of cost function :', len(str(cost_fn_sym)), '  ', len(str(cost_fn_sym))/1000, 'kB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4861e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_fn_sym = sym.simplify(cost_fn_sym) # this might take a bit of time\n",
    "print('Number of chars of cost function :', len(str(cost_fn_sym)), '  ', len(str(cost_fn_sym))/1000, 'kB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e125ac11",
   "metadata": {},
   "source": [
    "Define & lambdify gradient function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaa3e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sym.Matrix([cost_fn_sym.diff(var) for var in [k, p, o, x, y, z]])\n",
    "# g = g.applyfunc(sym.simplify) # does not change anything\n",
    "\n",
    "g_x_sym = lambda x0: g.subs({k: float(x0[0]), p: float(x0[1]), o: float(x0[2]), \n",
    "                             x: float(x0[3]), y: float(x0[4]), z: float(x0[5])})\n",
    "g_x = lambda x0: np.array(g_x_sym(x0).tolist()).astype('float')\n",
    "print('Check gradient (= 0): ', np.linalg.norm(g_x(x_gt)))\n",
    "print('Number of chars of gradient function :', len(str(g)), '  ', len(str(g))/1000, 'kB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d5a62b",
   "metadata": {},
   "source": [
    "Define & lambdify Hessian matrix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12d5dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = sym.hessian(cost_fn_sym, [k, p, o, x, y, z])\n",
    "#H = H.applyfunc(sym.simplify) # only small imporvement: 7280 vs. 7338 chars\n",
    "\n",
    "H_x_sym = lambda x0: H.subs({k: float(x0[0]), p: float(x0[1]), o: float(x0[2]), \n",
    "                             x: float(x0[3]), y: float(x0[4]), z: float(x0[5])})\n",
    "H_x = lambda x0: np.array(H_x_sym(x0).tolist()).astype('float')\n",
    "\n",
    "print('Shape of Hessian (= (6,6)) : ', H_x(x_gt).shape)\n",
    "print('Min value of Eigenvalues (> 0): ', np.min(np.linalg.eigvals(H_x(x_gt))))\n",
    "print('Number of chars of Hessian function :', len(str(H)), '  ', len(str(H))/1000, 'kB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2e5f34",
   "metadata": {},
   "source": [
    "Solve the problem with Newton's method. The method should exhibit quadratic convergence if x0 is \"good enough\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062d4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_framework(step_function, x0, x_gt):\n",
    "    print('Iteration # {:6s} {:18s} {:15s} {:20s}'.format('', 'delta gt', 'dx', 'dr'))\n",
    "    print('----------------------------------------------------------------')\n",
    "    def print_iter(iter_num, chk, dx, dr):\n",
    "        print('Iteration #{:d} {:15.8f} {:15.8f} {:15.8f}'.format(iter_num, chk, dx, dr))\n",
    "\n",
    "    dx = np.inf\n",
    "    iter_num = 0\n",
    "\n",
    "    print_iter(iter_num, np.linalg.norm(x0 - x_gt), np.nan, np.linalg.norm(g_x(x0)))\n",
    "    while np.linalg.norm(dx) > 1e-6 and iter_num < 100:\n",
    "        iter_num += 1\n",
    "        dx = step_function(x0)\n",
    "        x0 = x0 - dx\n",
    "        print_iter(iter_num, np.linalg.norm(x0 - x_gt), np.linalg.norm(dx), np.linalg.norm(r_x(x0)))\n",
    "        \n",
    "    print('Check solution ( =0): ', np.linalg.norm(x0 - x_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d7960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([45.0-15.0, -15.0+25.0, 20.0+25.0, 1.0+1.5, -2.0+1.8, 3.0-1.2]) # converging to the solution in 8 iterations\n",
    "#x0 = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0]) # converging to a local minimum in 20 iteration\n",
    "x0[:3] *= 1.0/180.0*pi\n",
    "\n",
    "def newton_step(x):\n",
    "    dx = np.linalg.inv(H_x(x)) @ g_x(x)\n",
    "    return dx.reshape(-1)\n",
    "\n",
    "optimizer_framework(newton_step, x0, x_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6af307",
   "metadata": {},
   "source": [
    "It seems this solution is also sensitive for the initial guess."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c6fac9",
   "metadata": {},
   "source": [
    "# Solution of the cost with built-in methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0bda83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed59fe31",
   "metadata": {},
   "source": [
    "For better convergence properties, we can do line search with the Hessian. In the next we will use [built-in](https://docs.scipy.org/doc/scipy/tutorial/optimize.html#newton-conjugate-gradient-algorithm-method-newton-cg) function that utilizes this technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec85fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_per_iter = []\n",
    "def iter_callback(xk):\n",
    "    dx_gt = np.linalg.norm(xk - x_gt)\n",
    "    cost_per_iter.append(dx_gt)\n",
    "    print('Norm from GT: ', dx_gt)\n",
    "\n",
    "x0 = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0]) # converging to the solution in 37 iterations\n",
    "res = minimize(lambda x: np.linalg.norm(r_x(x)), x0, method='Newton-CG',\n",
    "               jac=lambda x: g_x(x).reshape(-1),  hess=H_x,\n",
    "               options={'xtol': 1e-6, 'disp': True, 'maxiter': 50}, callback=iter_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058870ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(len(cost_per_iter)), cost_per_iter, '.-')\n",
    "plt.yscale('log')\n",
    "plt.grid(True,which=\"both\", linestyle='-.')\n",
    "plt.ylabel('log(norm(x_hat - x_gt))')\n",
    "plt.xlabel('iteration #')\n",
    "plt.title(\"Convergence of Newton-CG method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b597169d",
   "metadata": {},
   "source": [
    "# Solution with Gauss-Newton method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1924062",
   "metadata": {},
   "source": [
    "We should take advantage of the fact that the problem is least squares. This will allow us to use more stable algorithms with faster convergence rate and with less sensitivity to the initial guess."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830661f6",
   "metadata": {},
   "source": [
    "Create the Jacobian matrix for the least squares problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad67c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "J = res_sym_vec.jacobian([k, p, o, x, y, z])\n",
    "J_x_sym = lambda x0: J.subs({k: float(x0[0]), p: float(x0[1]), o: float(x0[2]), \n",
    "                             x: float(x0[3]), y: float(x0[4]), z: float(x0[5])})\n",
    "J_x = lambda x0: np.array(J_x_sym(x0).tolist()).astype('float')\n",
    "N = J_x(x0).T @ J_x(x0)\n",
    "\n",
    "\n",
    "print('Shape of Jacobian: ', J.shape)\n",
    "print('Shape of N: ', N.shape)\n",
    "print('Number of chars of Jacobian function :', len(str(J)), '  ', len(str(J))/1000, 'kB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e427b0b9",
   "metadata": {},
   "source": [
    "... and the iterations looks more stable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475fd49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0]) # converging to the solution in 5 iterations\n",
    "\n",
    "def gauss_newton_full_step(x):\n",
    "    dr = r_x(x)\n",
    "    dx =  np.linalg.inv(J_x(x).T @ J_x(x)) @ J_x(x).T @ dr\n",
    "    return dx\n",
    "\n",
    "optimizer_framework(gauss_newton_full_step, x0, x_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1667548",
   "metadata": {},
   "source": [
    "Surpresingly, almost quadratic convergence from the beginning with an initial guess far from the solution. However the above approach results in long Jacobian code. Instead we can compute the symbolic Jacobian for each point separatetly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5794cf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_x, m_y, m_z = sym.symbols('m_x m_y m_z')\n",
    "t_x, t_y, t_z = sym.symbols('t_x t_y t_z')\n",
    "\n",
    "m_xyz = np.array([m_x, m_y, m_z])\n",
    "t_xyz = np.array([t_x, t_y, t_z])\n",
    "\n",
    "dt_sym_row = np.array([x, y, z])\n",
    "eq_sym = (R_sym @ m_xyz).T + dt_sym_row - t_xyz\n",
    "\n",
    "print('Shape of a single point pair equation: (= (3,))', eq_sym.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb09c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "J_point_tx = sym.Matrix([eq_sym[0].diff(x) for x in [k, p, o, x, y, z]]).T\n",
    "J_point_ty = sym.Matrix([eq_sym[1].diff(x) for x in [k, p, o, x, y, z]]).T\n",
    "J_point_tz = sym.Matrix([eq_sym[2].diff(x) for x in [k, p, o, x, y, z]]).T\n",
    "J_point = sym.Matrix([J_point_tx, J_point_ty, J_point_tz])\n",
    "\n",
    "print('Number of chars of Jacobian function :', len(str(J_point)), '  ', len(str(J_point))/1000, 'kB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e748d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "J_point_sym = lambda x0, m_pt, t_pt: J_point.subs({k: float(x0[0]), p: float(x0[1]), o: float(x0[2]), \n",
    "                                                   x: float(x0[3]), y: float(x0[4]), z: float(x0[5]),\n",
    "                                                m_x: float(m_pt[0]), m_y: float(m_pt[1]), m_z: float(m_pt[2]),\n",
    "                                                t_x: float(t_pt[0]), t_y: float(t_pt[1]), t_z: float(t_pt[2])})\n",
    "\n",
    "J_point_x = lambda x0, m_pt, t_pt: np.array(J_point_sym(x0, m_pt, t_pt).tolist()).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6246070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_J(x):\n",
    "    J_x = np.zeros((pts_model.shape[0]*3, 6))\n",
    "    for pt_k in range(pts_model.shape[0]):\n",
    "        J_x[(pt_k*3):(pt_k*3+3)] = J_point_x(x, pts_model[pt_k, :], pts_target[pt_k, :])\n",
    "    return J_x\n",
    "\n",
    "print('Check Jacobian composition ( =0): ', np.linalg.norm(build_J(x_gt) - J_x(x_gt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b595df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0]) # converging to the solution in 5 iterations\n",
    "\n",
    "def gauss_newton_step(x):\n",
    "    dr = r_x(x)\n",
    "    dx = np.linalg.inv(build_J(x).T @ build_J(x)) @ build_J(x).T @ dr\n",
    "    return dx\n",
    "    \n",
    "optimizer_framework(gauss_newton_step, x0, x_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67f3a0e",
   "metadata": {},
   "source": [
    "# Solution with least squares and numerical differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc8f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import least_squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69b64ad",
   "metadata": {},
   "source": [
    "There are deravitive-free least squares algorithms that we can utilize to solve these types of problems faster & easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59cda76",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([0, 0, 0, 0, 0, 0])\n",
    "res = least_squares(r_x, x0, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dc3316",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Check solution ( =0): ', np.linalg.norm(res.x - x_gt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce3ab0a",
   "metadata": {},
   "source": [
    "# Solution with automatic differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de18853",
   "metadata": {},
   "source": [
    "Follow this link: https://sidsite.com/posts/autodiff/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25eecb4",
   "metadata": {},
   "source": [
    "- Operations are primarly implemented as overloads\n",
    "- All values are float inside the class\n",
    "- We provide constant (number) overloads for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b44ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class Variable(object):\n",
    "    \n",
    "    def __init__(self, value, local_gradients=[]):\n",
    "        self.value = float(value)\n",
    "        self.local_gradients = local_gradients\n",
    "\n",
    "    def __float__(self):\n",
    "         return self.value\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if not isinstance(other, Variable):\n",
    "            return self.__add__(Variable(float(other)))        \n",
    "        value = self.value + other.value    \n",
    "        local_gradients = ((self, 1.0), (other, 1.0))\n",
    "        return Variable(value, local_gradients)\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        if not isinstance(other, Variable):\n",
    "            return self.__mul__(Variable(float(other)))\n",
    "        value = self.value * other.value\n",
    "        local_gradients = ((self, other.value), (other, self.value))\n",
    "        return Variable(value, local_gradients)\n",
    "\n",
    "    def __neg__(self):\n",
    "        value = -1.0 * self.value\n",
    "        local_gradients = ((self, -1.0),)\n",
    "        return Variable(value, local_gradients)\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        if not isinstance(other, Variable):\n",
    "            return self.__sub__(Variable(float(other)))        \n",
    "        return self.__add__(other.__neg__())\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.value) + 'v' # + ' [' + str(self.local_gradients) + ']'\n",
    "\n",
    "    __radd__  = __add__\n",
    "    __rmul__ = __mul__\n",
    "    __rsub__ = __sub__\n",
    "\n",
    "class VarFunctions(object):\n",
    "    \n",
    "    @staticmethod\n",
    "    def sin(a):\n",
    "        value = np.sin(a.value)\n",
    "        local_gradients = (\n",
    "            (a, np.cos(a.value)),\n",
    "        )\n",
    "        return Variable(value, local_gradients)\n",
    "    \n",
    "    @staticmethod\n",
    "    def cos(a):\n",
    "        value = np.cos(a.value)\n",
    "        local_gradients = (\n",
    "            (a, -np.sin(a.value)),\n",
    "        )\n",
    "        return Variable(value, local_gradients)\n",
    "\n",
    "vf = VarFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fd2789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradients(variable):\n",
    "    \n",
    "    gradients = defaultdict(lambda: 0)\n",
    "    \n",
    "    def compute_gradients(variable, path_value):\n",
    "        for child_variable, local_gradient in variable.local_gradients:\n",
    "            # \"Multiply the edges of a path\":\n",
    "            value_of_path_to_child = path_value * local_gradient\n",
    "            # \"Add together the different paths\":\n",
    "            gradients[child_variable] += value_of_path_to_child\n",
    "            # recurse through graph:\n",
    "            compute_gradients(child_variable, value_of_path_to_child)\n",
    "    \n",
    "    compute_gradients(variable, path_value=1)\n",
    "    # (path_value=1 is from `variable` differentiated w.r.t. itself)\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c7c22d",
   "metadata": {},
   "source": [
    "Test a basic operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e195a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a = Variable(4)\n",
    "test_b = Variable(4)\n",
    "test_c = test_a - test_b\n",
    "print(test_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe0159f",
   "metadata": {},
   "source": [
    "Let's redefine rotations using the newly created functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afcc1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rx_(theta):\n",
    "  return np.array([[ 1, 0           , 0           ],\n",
    "                   [ 0, vf.cos(theta),-vf.sin(theta)],\n",
    "                   [ 0, vf.sin(theta), vf.cos(theta)]])\n",
    "  \n",
    "def Ry_(theta):\n",
    "  return np.array([[vf.cos(theta), 0, vf.sin(theta)],\n",
    "                   [ 0           , 1, 0           ],\n",
    "                   [-vf.sin(theta), 0, vf.cos(theta)]])\n",
    "  \n",
    "def Rz_(theta):\n",
    "  return np.array([[vf.cos(theta), -vf.sin(theta), 0 ],\n",
    "                   [ vf.sin(theta), vf.cos(theta) , 0 ],\n",
    "                   [ 0           , 0            , 1 ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9b9347",
   "metadata": {},
   "source": [
    "We create a convieince function to convert from numpy to a list of Variables, and then, we define the lambda function for the rotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7898ce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "np2var = lambda vec: [Variable(x) for x in vec]\n",
    "x_gt_ad = np2var(x_gt) \n",
    "ypr2rot_ad = lambda x: Rz_(x[0]) @ Ry_(x[1]) @ Rx_(x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a1bbd4",
   "metadata": {},
   "source": [
    "We can check the function whether it's correctly working. Note that we can nicely use the numpy infrastructure due to the overloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e43dcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_ad = ypr2rot_ad(x_gt_ad)\n",
    "dR_chk = (R_ad - R_gt).astype('float') # Variable ->  conversion works nicely\n",
    "\n",
    "print('Check rotation composition ( =0): ', np.linalg.norm(dR_chk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510c0a3e",
   "metadata": {},
   "source": [
    "Next we need to define the conversion from 2d numpy float arrays to arrays of Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70db467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array2var(arr):\n",
    "    var_arr = np.zeros(arr.shape, dtype=Variable)\n",
    "    for i in range(arr.shape[0]):\n",
    "        for j in range(arr.shape[1]):\n",
    "            var_arr[i, j] = Variable(arr[i, j])\n",
    "    return var_arr\n",
    "            \n",
    "pts_model_ad = array2var(pts_model)  \n",
    "pts_target_ad = array2var(pts_target)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06526135",
   "metadata": {},
   "source": [
    "Now we have everything to write down the residual vector as a lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce23a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_x_ad = lambda x0: ((ypr2rot_ad(x0) @ pts_model.T).T + np.array([x0[3:6]]) - pts_target).ravel()\n",
    "\n",
    "print('Check residual vector ( =0): ', np.linalg.norm((r_x_ad(x_gt_ad) - r_x(x_gt_ad)).astype('float')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3c33bd",
   "metadata": {},
   "source": [
    "Note that the residual function will give us back a vector of Variable types, on which we can compute the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01527c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ad = r_x_ad(x_gt_ad)\n",
    "grad_chk = get_gradients(r_ad[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ea1aeb",
   "metadata": {},
   "source": [
    "This gradient will be the entries of the Jacobian. Let's compare one entry to the entry of the Jacobian matrix computed earlier using symbolic calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507a54b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "J_gt = build_J(x_gt)\n",
    "print('Check Jacobian entry: ', J_gt[0, 1] - grad_chk[x_gt_ad[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30559cae",
   "metadata": {},
   "source": [
    "A bit of work, but we can now compose the Jacobian using the auto-diff nano framework. We go through each residual vector element, and then, through each parameter entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f0a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_J_ad(r, x):\n",
    "    m = r.shape[0]\n",
    "    n = 6\n",
    "    J = np.zeros((m, n))\n",
    "    for iter_r in range(m):\n",
    "        grad_iter = get_gradients(r[iter_r])\n",
    "        for iter_x in range(n):\n",
    "            J[iter_r, iter_x] = grad_iter[x[iter_x]]\n",
    "    return J\n",
    "\n",
    "J_ad = build_J_ad(r_ad, x_gt_ad)\n",
    "print('Check Jacobian ( =0): ', np.linalg.norm(J_ad - J_gt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678ddf19",
   "metadata": {},
   "source": [
    "Finally, we can run our Newton-Gauss method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2abebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_newton_autodiff_step(x):\n",
    "    dr = r_x(x)\n",
    "\n",
    "    # autodiff code\n",
    "    x_ad = np2var(x)\n",
    "    dr_ad = r_x_ad(x_ad)\n",
    "    J_ad = build_J_ad(dr_ad, x_ad)\n",
    "    \n",
    "    dx = np.linalg.inv(J_ad.T @ J_ad) @ J_ad.T @ dr\n",
    "    \n",
    "    return dx\n",
    "\n",
    "x0 = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0]) # converging to the solution in 5 iterations\n",
    "optimizer_framework(gauss_newton_autodiff_step, x0, x_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9860e99",
   "metadata": {},
   "source": [
    "The iteration steps and results are exactly identical to the case when we used the symbolic library to compute the Jacobian. This code is extremely fast beating most of the earlier implementaions! This solution seems to be the fastest implementation in the notebook so far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c015e67",
   "metadata": {},
   "source": [
    "# Changing parametrization: Solution with rotation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79633042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_x_12(x, pts_model, pts_target):\n",
    "    x_R = x[0:9]\n",
    "    R = x_R.reshape(3,3)\n",
    "    return ((R @ pts_model.T).T + np.array([x[9:12]]) - pts_target).ravel()\n",
    "\n",
    "x_gt_12 = np.hstack((R_gt.ravel(), x_gt[3:6]))\n",
    "print('Check r_x_12 ( =0): ', np.linalg.norm(r_x_12(x_gt_12, pts_model, pts_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1627daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x0 = np.array([45.0-1.0, -15.0+2.0, 20.0+1.0, 1.0+0.5, -2.0+0.8, 3.0-0.2])\n",
    "x0 = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "x0[:3] *= 1.0/180.0*math.pi\n",
    "R0_12 = Rotation.from_euler('ZYX', x0[:3], degrees=False).as_matrix()\n",
    "x0_12 = np.hstack((R0_12.ravel(), x0[3:6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b6a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(lambda x: np.linalg.norm(r_x_12(x, pts_model, pts_target)), x0_12, method='trust-constr',\n",
    "               options={'disp': True, 'maxiter': 2000})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3c19e9",
   "metadata": {},
   "source": [
    "It's less suprising that the optimizer converged, bus it is more supresing that the optimizer actually found the solution! Check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eac918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_hat_12 = res.x[0:9].reshape(3,3)\n",
    "print('Final cost: ', np.linalg.norm(r_x_12(res.x, pts_model, pts_target)))\n",
    "print('Solutions as angles: ', Rotation.from_matrix(R_hat_12).as_euler('ZYX', degrees=True))\n",
    "print(' ')\n",
    "print('Compare solution to GT: ( =0)', np.linalg.norm(res.x - x_gt_12))\n",
    "print('Compare rotation matrix to GT: ( =0)', np.linalg.norm(R_gt - R_hat_12))\n",
    "print('Check rotation m. orthogonality: ( =0): ', np.linalg.norm(R_hat_12.T @ R_hat_12 - np.eye(3)))\n",
    "print('Check rotation m. determinant ( =1): ', np.linalg.det(R_hat_12))\n",
    "print('GT determinant ( =1): ', np.linalg.det(R_gt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f1925d",
   "metadata": {},
   "source": [
    "The Euler angles look pretty close to the ground truth, and the orthogonality condition is automatically satisfied without constraints. So I thought this is because the system is overdetermined. Let's see the results when I pick the minimum problem (with the minimum number of points):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357df9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(lambda x: np.linalg.norm(r_x_12(x, pts_model[:4], pts_target[:4])), x0_12, method='trust-constr',\n",
    "               options={'disp': True, 'maxiter': 2000})\n",
    "\n",
    "R_hat_12 = res.x[0:9].reshape(3,3)\n",
    "\n",
    "print('Final cost: ', np.linalg.norm(r_x_12(res.x, pts_model[:4], pts_target[:4])))\n",
    "print('Solutions as angles: ', Rotation.from_matrix(R_hat_12).as_euler('ZYX', degrees=True))\n",
    "print(' ')\n",
    "print('Check rotation m. orthogonality: ( =0): ', np.linalg.norm(R_hat_12.T @ R_hat_12 - np.eye(3)))\n",
    "print('Check rotation m. determinant ( =1): ', np.linalg.det(R_hat_12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d9b3b6",
   "metadata": {},
   "source": [
    "It's quite good! I need to go to an underdetermined case to get non-orthogonal solution for the rotation matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0128ee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([45.0-10.0, -15.0+2.0, 20.0+1.0, 1.0+0.5, -2.0+0.8, 3.0-0.2])\n",
    "x0[:3] *= 1.0/180.0*math.pi\n",
    "R0_12 = Rotation.from_euler('ZYX', x0[:3], degrees=False).as_matrix()\n",
    "x0_12 = np.hstack((R0_12.ravel(), x0[3:6]))\n",
    "\n",
    "res = minimize(lambda x: np.linalg.norm(r_x_12(x, pts_model[:3], pts_target[:3])), x0_12, method='trust-constr',\n",
    "               options={'disp': True, 'maxiter': 2000})\n",
    "\n",
    "R_hat_12 = res.x[0:9].reshape(3,3)\n",
    "\n",
    "print('Final cost: ', np.linalg.norm(r_x_12(res.x, pts_model[:4], pts_target[:4])))\n",
    "print('Solutions as angles: ', Rotation.from_matrix(R_hat_12).as_euler('ZYX', degrees=True))\n",
    "print(' ')\n",
    "print('Check rotation m. orthogonality: ( =0): ', np.linalg.norm(R_hat_12.T @ R_hat_12 - np.eye(3)))\n",
    "print('Check rotation m. determinant ( =1): ', np.linalg.det(R_hat_12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8ae37c",
   "metadata": {},
   "source": [
    "So now I can show-case how to fix this issue with constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55afc21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "const = ({'type': 'eq', 'fun': lambda x:  (x[0:9].reshape(3,3).T @ x[0:9].reshape(3,3) - np.eye(3))[0,0]},\n",
    "        {'type': 'eq', 'fun': lambda x:  (x[0:9].reshape(3,3).T @ x[0:9].reshape(3,3) - np.eye(3))[0,1]},\n",
    "        {'type': 'eq', 'fun': lambda x:  (x[0:9].reshape(3,3).T @ x[0:9].reshape(3,3) - np.eye(3))[0,2]},\n",
    "        {'type': 'eq', 'fun': lambda x:  (x[0:9].reshape(3,3).T @ x[0:9].reshape(3,3) - np.eye(3))[1,0]},\n",
    "        {'type': 'eq', 'fun': lambda x:  (x[0:9].reshape(3,3).T @ x[0:9].reshape(3,3) - np.eye(3))[1,1]},\n",
    "        {'type': 'eq', 'fun': lambda x:  (x[0:9].reshape(3,3).T @ x[0:9].reshape(3,3) - np.eye(3))[1,2]},\n",
    "        {'type': 'eq', 'fun': lambda x:  (x[0:9].reshape(3,3).T @ x[0:9].reshape(3,3) - np.eye(3))[2,0]},\n",
    "        {'type': 'eq', 'fun': lambda x:  (x[0:9].reshape(3,3).T @ x[0:9].reshape(3,3) - np.eye(3))[2,1]},\n",
    "        {'type': 'eq', 'fun': lambda x:  (x[0:9].reshape(3,3).T @ x[0:9].reshape(3,3) - np.eye(3))[2,2]})\n",
    "\n",
    "res = minimize(lambda x: np.linalg.norm(r_x_12(x, pts_model[:4], pts_target[:4])), x0_12, method='trust-constr',\n",
    "               options={'disp': True, 'maxiter': 2000}, constraints=const)\n",
    "\n",
    "R_hat_12 = res.x[0:9].reshape(3,3)\n",
    "\n",
    "print('Final cost: ', np.linalg.norm(r_x_12(res.x, pts_model[:4], pts_target[:4])))\n",
    "print('Solutions as angles: ', Rotation.from_matrix(R_hat_12).as_euler('ZYX', degrees=True))\n",
    "print(' ')\n",
    "print('Check rotation m. orthogonality: ( =0): ', np.linalg.norm(R_hat_12.T @ R_hat_12 - np.eye(3)))\n",
    "print('Check rotation m. determinant ( =1): ', np.linalg.det(R_hat_12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb99e81",
   "metadata": {},
   "source": [
    "Of course having 9 parameters to describe the rotation is not ideal. For one, Euler parameterization converges faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59955d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([0, 0, 0, 0, 0, 0]) # converges to the solution in 149 iterations\n",
    "res = minimize(lambda x: np.linalg.norm(r_x(x)), x0, method='trust-constr',\n",
    "               options={'disp': True, 'maxiter': 2000})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bd12c2",
   "metadata": {},
   "source": [
    "# Solution with Lie algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc02990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7333ae5",
   "metadata": {},
   "source": [
    "- https://www.ethaneade.com/lie.pdf\n",
    "- Graph-base SLAM tutorial: http://ais.informatik.uni-freiburg.de/teaching/ws11/robotics2/pdfs/ls-slam-tutorial.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81861aa4",
   "metadata": {},
   "source": [
    "The theme will be the followings:\n",
    "\n",
    "TODO: this need to be in a reverse direction!\n",
    "\n",
    "1. We have a known rotation representation (e.g. rotation matrix, quaternion) to simply perform an \"action\" called rotation on points represented with 3D vectors. However these representations are over-parametrizations of the rotation (for rotation matrix it is 9 and for quaternion it is 4 vs. the minimal representation composed of only 3 parameters). We saw that we needed constraints when using non-minimal rotation representation. To avoid using constraints, We consider special properties of these transformations. These transformations are special mathematical structures called  Lie groups, i.e. SO(3) for rotation matrices and S(4) for quaternions.\n",
    "\n",
    "2. We will have conversion from the Lie group to another mathematical structure called the Lie algebra. The Lie algebra of rotation matrices is so(3) skew matrices and for quaternions it is S(3) unit quaternions. This conversion or mapping between the group and its algebra is called the logarithmic  map. \n",
    "\n",
    "3. The Lie algebra is isomorphic with an n-dimensional vector space. In our case, it means that for each element of so(3) or S(3) I can assign a vector from a 3D vector space. Therefore, we will have a R^3 minimal represention of rotations in the continous vector space. Then, we can optimization without having worried about constraints, however we don't have a direct mathematical formula to apply rotation on a point represented by a vector as we had in the Lie groups.\n",
    "\n",
    "These steps can be reversed. In this case we need to invert the logarithmic map; this mapping is called exponential map. During optimization we can do both operations to change from one representation to the other depending on whether we perform the rotation or update the optimizer step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc956a",
   "metadata": {},
   "source": [
    "Dictionary:\n",
    "- Lie groups: rotation representation with wich we can directly perform rotation, e.g. rotation matrix, quaternion.\n",
    "- Lie algebra: some intermidiate representation between the Lie group and R^3, e.g. skew matrix for rotation matrix and unit quaternions for quaternions.\n",
    "- exponential map: conversion\n",
    "- logarithmic map: conversion\n",
    "- isomporphic: basically the same space just operations defined a bit differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3392bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rvec_gt = Rotation.from_euler('ZYX', ypr_gt, degrees=False).as_rotvec(degrees=False)\n",
    "print('Rotation vector:', rvec_gt)\n",
    "print('Rotation angle around the axis (omega):', np.linalg.norm(rvec_gt) / pi * 180)\n",
    "print('Rotation axis: ', rvec_gt / np.linalg.norm(rvec_gt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b335b5",
   "metadata": {},
   "source": [
    "The converstion takes two steps: first from vector space to so(3), and then from so(3) to SO(3). I'm following here the lecture notes on [Lie Groups for 2D and 3D Transformations by Ethan Eade](https://www.ethaneade.com/lie.pdf).\n",
    "\n",
    "Generator system to compute the skew symmetric matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16761077",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = np.array([[0, 0, 0], [0, 0, -1], [0, 1, 0]])\n",
    "G2 = np.array([[0, 0, 1], [0, 0, 0], [-1, 0, 0]])\n",
    "G3 = np.array([[0, -1, 0], [1, 0, 0], [0, 0, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad140b8",
   "metadata": {},
   "source": [
    "Then, we can write the function that converts from rotation vector representation (R^3) to skew symmetric matrix (so(3)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2049ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew = lambda w: w[0]*G1 + w[1]*G2 + w[2]*G3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a90122",
   "metadata": {},
   "source": [
    "Note that the skew symmetric matrix allows for descring cross product with purely using matrix multiplication. In this sense the skew matrix can be viewed as \"changing\" the group operation from cross product to matrix-vector multiplication (R^3, x) = (R^3, []_x*) . Since both operations results in the exactly the same results applied on the all R^3 vectors, therefore the two groups are isomorphic.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4010e00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_a = [-2, 3, 1]\n",
    "w_b = np.array([4, -8, 2]).reshape(-1)\n",
    "\n",
    "print('[a]_x * b = ', skew(w_a) @ w_b)\n",
    "print('a x b =, ', np.cross(w_a, w_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c4705",
   "metadata": {},
   "source": [
    "Then we can take the skew matrix (so(3)) and apply the exponential map to it; the result is the rotation matrix. The derivation can be found in a lecture notes titled [Lie Groups for 2D and 3D Transformations by Ethan Eade, Page 3-4](https://www.ethaneade.com/lie.pdf). This conversion formula is also known as the Rodrigues' rotation formula, see it on [Wikipedia](https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2588cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_gt = np.sqrt(rvec_gt.T @ rvec_gt) # = np.linalg.norm(rvec)\n",
    "S_gt = skew(rvec_gt)\n",
    "R_gt_lie = np.eye(3) + (math.sin(omega_gt)/omega_gt)*S_gt + ((1-math.cos(omega_gt))/omega_gt**2)*S_gt@S_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaae03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#R_gt = Rotation.from_euler('ZYX', ypr_gt, degrees=False).as_matrix()\n",
    "print('Check calculation: ', np.linalg.norm(R_gt_lie - R_gt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3486c200",
   "metadata": {},
   "source": [
    "Let's visualize these mathematical structures and make sense of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc45b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tangent_pt = np.array([1, 0, 0])\n",
    "\n",
    "# Let's create the surfaces by visualizing their transformation on a 3D vector tangent_pt\n",
    "SO3_surface = []\n",
    "so3_surface = []\n",
    "for yaw in np.arange(-pi, pi, 0.3):                    # sample points at possible Euler \n",
    "  for pitch in np.arange(-pi, pi, 0.3):                # angles to construct SO(3)\n",
    "    for roll in np.arange(-pi, pi, 0.3):\n",
    "        R = R_x([yaw, pitch, roll])                    # construct rotation matrix SO(3)\n",
    "        pt_ = R @ tangent_pt                         \n",
    "        SO3_surface.append(pt_)\n",
    "        \n",
    "        omega = np.arccos((np.trace(R)-1)/2)        \n",
    "        S = (omega/(2*np.sin(omega))) * (R - R.T)      # SO(3) -> so(3)\n",
    "        pt_ = S @ tangent_pt\n",
    "        so3_surface.append(pt_)\n",
    "\n",
    "SO3_surface = np.array(SO3_surface)\n",
    "so3_surface = np.array(so3_surface)\n",
    "so3_surface += tangent_pt                              # this will move the points to the identity SO(3) * tangent_pt\n",
    "\n",
    "# plotting the SO(3) and so(3) surfaces\n",
    "plt.figure(figsize=(6,5))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(SO3_surface[:,0], SO3_surface[:,1], SO3_surface[:,2], c='r', s=0.1, alpha=0.2)\n",
    "ax.scatter3D(so3_surface[:,0], so3_surface[:,1], so3_surface[:,2], c='b', s=0.1, alpha=0.2)\n",
    "\n",
    "# We will create a trajectory in R^3 and show how this trajectory looks like in so(3) and SO(3)\n",
    "SO3_line = []\n",
    "so3_line = []\n",
    "for w_i in np.arange(0.0001, pi, 0.1):\n",
    "    w = [0, 0, w_i]\n",
    "    S = np.array([[0, -w[2], w[1]], [w[2], 0, -w[0]], [-w[1], w[0], 0]])            # R^3 -> so(3)\n",
    "    pt_ = S @ tangent_pt\n",
    "    so3_line.append(pt_)\n",
    "\n",
    "    omega = (w[0]**2 + w[1]**2 + w[2]**2)**(1/2)\n",
    "    R = np.eye(3) + (math.sin(omega)/omega)*S + ((1-math.cos(omega))/omega**2)*S@S  # so(3) -> SO(3)\n",
    "    pt_ = R @ tangent_pt\n",
    "    SO3_line.append(pt_)\n",
    "\n",
    "SO3_line = np.array(SO3_line)\n",
    "so3_line = np.array(so3_line)\n",
    "so3_line += tangent_pt \n",
    "\n",
    "# plotting the trajectory\n",
    "ax.plot3D(SO3_line[:,0], SO3_line[:,1], SO3_line[:,2], 'k.-', markersize=6)\n",
    "ax.plot3D(so3_line[:,0], so3_line[:,1], so3_line[:,2], 'k.-', markersize=6)\n",
    "set_3d_axes_equal(ax)\n",
    "ax.view_init(elev=25, azim=120)\n",
    "ax.set_title('SO(3) Lie group of rotation matrices and\\n so(3) Lie algebra of skew matrices')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c941c12",
   "metadata": {},
   "source": [
    "Let's do exponential map in a more compact form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6f8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Exp_(w):\n",
    "    omega = (w[0]**2 + w[1]**2 + w[2]**2)**(1/2)\n",
    "    S = np.array([[0, -w[2], w[1]], [w[2], 0, -w[0]], [-w[1], w[0], 0]])\n",
    "    return np.eye(3) + (math.sin(omega)/omega)*S + ((1-math.cos(omega))/omega**2)*S@S\n",
    "\n",
    "print('Check exponential map: ', np.linalg.norm(Exp_(rvec_gt) - R_gt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695d6999",
   "metadata": {},
   "source": [
    "Reverse direction is easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9ffd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Log_(R):\n",
    "    omega = np.arccos((np.trace(R)-1)/2)           # input rotation matrix\n",
    "    S = (omega/(2*np.sin(omega))) * (R_gt-R_gt.T)  # rotation matrix SO(3) -> skew so(3)\n",
    "    return [S[2, 1], S[0, 2], S[1, 0]]             # so(3) -> R^3, using the def. of skew matrix\n",
    "\n",
    "print('Check log map: ', np.linalg.norm(Exp_(rvec_gt) - R_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14f2251",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_x_lie = lambda x0: ((Exp_(x0) @ pts_model.T).T + np.array([x0[3:6]]) - pts_target).ravel()\n",
    "x_gt_lie = np.hstack((rvec_gt, x_gt[3:6]))\n",
    "print('Check residual function ( =0): ', np.linalg.norm(r_x_lie(x_gt_lie)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9172176a",
   "metadata": {},
   "source": [
    "Let's compare the rotation vector parametrization with the Euler angle implementation using the built-in Nelder-Mead algorithm. As a reminder, here we want to directly solve the cost function, and we need to provide relatively good initial guess for convergence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a489fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_lie = np.array([45.0-15.0, -15.0+25.0, 20.0+25.0, 1.0+1.5, -2.0+1.8, 3.0-1.2]) # converging to the solution in ~1000 iterations\n",
    "#x0_lie = np.array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) # converging to a local minimum\n",
    "x0_lie[:3] *= 1.0/180.0*math.pi\n",
    "\n",
    "print('Solution with Euler angles: ')\n",
    "res = minimize(lambda x: np.linalg.norm(r_x(x)), x0_lie, method='nelder-mead',\n",
    "               options={'xatol': 1e-6, 'disp': True, 'maxiter': 2000})\n",
    "print('Check Euler angle solution ( =0): ', np.linalg.norm(res.x - x_gt))\n",
    "\n",
    "print(' ')\n",
    "\n",
    "print('Solution with rotation vectors: ')\n",
    "x0_lie[:3] = Rotation.from_euler('ZYX', x0_lie[:3], degrees=False).as_rotvec(degrees=False)\n",
    "res = minimize(lambda x: np.linalg.norm(r_x_lie(x)), x0_lie, method='nelder-mead',\n",
    "               options={'xatol': 1e-6, 'disp': True, 'maxiter': 2000})\n",
    "\n",
    "print('Check rotation vector solution ( =0): ', np.linalg.norm(res.x - x_gt_lie))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2822c63",
   "metadata": {},
   "source": [
    "Both algorithm converged with some initial guess, but starting at very poor initial guess (close to zero), both approaches fail. Seemingly, the rotation vector representation converges faster, which is why this approach is preferred in practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435b2bed",
   "metadata": {},
   "source": [
    "Advantages:\n",
    "- In general, using rotation vector representation results in faster convergence than the Euler angle representation, and therefore, it's preferred in practice. \n",
    "- Only one singular point, when in case of zero rotation, and it can be easily handled.\n",
    "\n",
    "Drawbacks:\n",
    "- This approach does not converge with deravtive-free optimizer when the initial guess is very poor. \n",
    "- When trying to debug the code, representation of rotation vectors is not easy to interpret. In practice the covariances of the Euler angles are easier to interpret as opposed to the rotation vectors'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74100a6d",
   "metadata": {},
   "source": [
    "# Operation counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f58c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a563d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OperationCounterClass(object):\n",
    "    table = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def reset():\n",
    "        for key in OperationCounter.table:\n",
    "            OperationCounter.table[key] = 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def incr(op):\n",
    "        if op in OperationCounter.table.keys():\n",
    "            OperationCounter.table[op] += 1\n",
    "        else:\n",
    "            OperationCounter.table[op] = 1         \n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.table)\n",
    "\n",
    "OperationCounter = OperationCounterClass() # so __repr__ works as expected\n",
    "\n",
    "def operation_counter_decorator(func):\n",
    "    OperationCounter.table[func.__name__] = 0\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        if len(args) == 1:\n",
    "            OperationCounter.incr(func.__name__)   \n",
    "        elif len(args) == 2:\n",
    "            self = args[0]\n",
    "            other = args[1]\n",
    "            if isinstance(other, Variable): # would be called twice if 'other' needs casting\n",
    "                OperationCounter.incr(func.__name__)   \n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "                        \n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93c9df5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class VariableCnt(Variable):\n",
    "       \n",
    "    def __init__(self, value, local_gradients=[]):\n",
    "        if isinstance(value, Variable):  \n",
    "            Variable.__init__(self, value.value, value.local_gradients)\n",
    "        else:\n",
    "            Variable.__init__(self, value, local_gradients)\n",
    "    \n",
    "    @operation_counter_decorator\n",
    "    def __add__(self, other):\n",
    "        return VariableCnt(Variable.__add__(self, other))\n",
    "    \n",
    "    @operation_counter_decorator\n",
    "    def __mul__(self, other):\n",
    "        return VariableCnt(Variable.__mul__(self, other))\n",
    "\n",
    "    @operation_counter_decorator\n",
    "    def __neg__(self):\n",
    "        return VariableCnt(Variable.__neg__(self))\n",
    "    \n",
    "    #@operation_counter # VariableCnt.var_operation_count['sub'] += 1 # subtraction is composed of neg and add so here we would duplicate count\n",
    "    def __sub__(self, other):\n",
    "        return VariableCnt(Variable.__sub__(self, other)) \n",
    "    \n",
    "    __radd__  = __add__\n",
    "    __rmul__ = __mul__\n",
    "    __rsub__ = __sub__\n",
    "    \n",
    "class VarFunctionsCnt(VarFunctions):\n",
    "    @staticmethod\n",
    "    @operation_counter_decorator\n",
    "    def sin(a):\n",
    "        return VariableCnt(VarFunctions.sin(a))\n",
    "    \n",
    "    @staticmethod\n",
    "    @operation_counter_decorator\n",
    "    def cos(a):\n",
    "        return VariableCnt(VarFunctions.cos(a))\n",
    "\n",
    "vf = VarFunctionsCnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53535982",
   "metadata": {},
   "outputs": [],
   "source": [
    "OperationCounter.reset()\n",
    "\n",
    "test_a = VariableCnt(1)\n",
    "test_b = VariableCnt(2)\n",
    "test_c = (test_a - vf.cos(test_b))*2\n",
    "\n",
    "print('Operation types and counts: ', OperationCounter)\n",
    "print('Value at the last variable ( !=0): ', test_c.value)\n",
    "print('Gradients at the last variable (= not []): ', test_c.local_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4117810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rx_(theta):\n",
    "  return np.array([[ 1, 0           , 0           ],\n",
    "                   [ 0, vf.cos(theta),-vf.sin(theta)],\n",
    "                   [ 0, vf.sin(theta), vf.cos(theta)]])\n",
    "  \n",
    "def Ry_(theta):\n",
    "  return np.array([[vf.cos(theta), 0, vf.sin(theta)],\n",
    "                   [ 0           , 1, 0           ],\n",
    "                   [-vf.sin(theta), 0, vf.cos(theta)]])\n",
    "  \n",
    "def Rz_(theta):\n",
    "  return np.array([[vf.cos(theta), -vf.sin(theta), 0 ],\n",
    "                   [ vf.sin(theta), vf.cos(theta) , 0 ],\n",
    "                   [ 0           , 0            , 1 ]])\n",
    "\n",
    "np2var = lambda vec, typeOf=VariableCnt: [typeOf(x) for x in vec]\n",
    "ypr2rot_ad = lambda x: Rz_(x[0]) @ Ry_(x[1]) @ Rx_(x[2])\n",
    "r_x_ad = lambda x0: ((ypr2rot_ad(x0) @ pts_model.T).T + np.array([x0[3:6]]) - pts_target).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d2956",
   "metadata": {},
   "source": [
    "Run a Gauss-Newton just to check that everything's ok..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ebb951",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0]) # converging to the solution in 5 iterations\n",
    "\n",
    "def gauss_newton_autodiff_count_step(x):\n",
    "    x_ad = np2var(x)\n",
    "    dr_ad = r_x_ad(x_ad)\n",
    "    dr_f = dr_ad.astype('float')\n",
    "    J_ad = build_J_ad(dr_ad, x_ad)\n",
    "    \n",
    "    dx = np.linalg.inv(J_ad.T @ J_ad) @ J_ad.T @ dr_f    \n",
    "    return dx\n",
    "\n",
    "optimizer_framework(gauss_newton_autodiff_count_step, x0, x_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1675159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "OperationCounter.reset()\n",
    "\n",
    "x0_ad = np2var(x0)\n",
    "dr_ad = r_x_ad(x0_ad)\n",
    "J_ad = build_J_ad(dr_ad, x0_ad)\n",
    "\n",
    "print('To be sure that type is correct ( =True): ', type(dr_ad[0]) is VariableCnt)\n",
    "print('Operations counts:', OperationCounter) # {'add': 154, 'mul': 136, 'neg': 3, 'sin': 6, 'cos': 6}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd24e8c",
   "metadata": {},
   "source": [
    "# Automatic differentation with rotation vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43049a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableExt(VariableCnt):\n",
    "            \n",
    "    def __init__(self, value, local_gradients=[]):\n",
    "        VariableCnt.__init__(self, value, local_gradients)\n",
    "    \n",
    "    def __pow__(self, other):\n",
    "        if isinstance(other, Variable) and other.value == 2: \n",
    "            OperationCounter.incr('pow2')\n",
    "        elif isinstance(other, Variable) and other.value == 0.5: \n",
    "            OperationCounter.incr('sqrt')\n",
    "        elif isinstance(other, Variable) and other.value < 1.0: \n",
    "            OperationCounter.incr('invpow')\n",
    "        elif isinstance(other, Variable):\n",
    "            OperationCounter.incr('pow')\n",
    "        \n",
    "        if not isinstance(other, Variable):\n",
    "            return self.__pow__(VariableExt(float(other)))                \n",
    "        value = self.value ** other.value\n",
    "        local_gradients = ((self,  other.value*self.value**(other.value-1) ), \n",
    "                           (other, self.value**other.value*math.log(other.value)))\n",
    "        return VariableExt(value, local_gradients)\n",
    "             \n",
    "    @operation_counter_decorator        \n",
    "    def __inv__(self):\n",
    "        value = 1. / self.value\n",
    "        local_gradients = (\n",
    "            (self, -1 / self.value**2),\n",
    "        )\n",
    "        return VariableExt(value, local_gradients)\n",
    "        \n",
    "    def __truediv__(self, other):\n",
    "        if not isinstance(other, Variable):\n",
    "            return self.__truediv__(VariableExt(float(other)))         \n",
    "        return self.__mul__(other.__inv__()) \n",
    "\n",
    "    def __add__(self, other):\n",
    "        return VariableExt(VariableCnt.__add__(self, other))\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        return VariableExt(VariableCnt.__mul__(self, other))\n",
    "\n",
    "    def __neg__(self):\n",
    "        return VariableExt(VariableCnt.__neg__(self))\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        return VariableExt(VariableCnt.__sub__(self, other)) \n",
    "    \n",
    "    __radd__  = __add__\n",
    "    __rmul__ = __mul__\n",
    "    __rsub__ = __sub__\n",
    "        \n",
    "class VarFunctionsExt(VarFunctionsCnt):\n",
    "\n",
    "    @staticmethod\n",
    "    def sin(a):\n",
    "        if not isinstance(a, Variable):\n",
    "            return VarFunctionsExt.sin(VariableExt(float(a)))                \n",
    "        return VariableExt(VarFunctionsCnt.sin(a))\n",
    "    \n",
    "    @staticmethod\n",
    "    def cos(a):\n",
    "        if not isinstance(a, Variable):\n",
    "            return VarFunctionsExt.cos(VariableExt(float(a)))                \n",
    "        return VariableExt(VarFunctionsCnt.cos(a))\n",
    "\n",
    "vf = VarFunctionsExt\n",
    "_var = VariableExt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac8b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "OperationCounter.reset()\n",
    "\n",
    "test_a = _var(3)\n",
    "test_b = _var(4)\n",
    "test_c = (test_a**2 + test_b**2)**(_var(1)/_var(2))\n",
    "print('Test value ( =5): ', test_c.value)\n",
    "print('Local gradient ( not =[]): ', test_c.local_gradients)\n",
    "\n",
    "print('Number of operations: ', OperationCounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2844f70a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_gt_al = np.hstack((rvec_gt, x_gt[3:6]))\n",
    "\n",
    "def Exp_al_(w):\n",
    "    omega = (w[0]**2 + w[1]**2 + w[2]**2)**(1/2) # some modification here, because we need to use elementary operations\n",
    "    S = np.array([[0, -w[2], w[1]], [w[2], 0, -w[0]], [-w[1], w[0], 0]])\n",
    "    # need to change the scalar * matrix order to matrix * scalar & convert all constants to VariableExt\n",
    "    R = np.eye(3) + S*(vf.sin(omega)/omega) + S@S*((_var(1)-vf.cos(omega))/omega**2)\n",
    "    return R\n",
    "\n",
    "R_gt_al = Exp_al_(np2var(x_gt_al, typeOf=VariableExt))\n",
    "print(np.linalg.norm((R_gt_al - R_gt).astype('float')))\n",
    "print(R_gt_al[0,0].local_gradients)\n",
    "print(type(R_gt_al[0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7733dc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_x_al = lambda x0: ((Exp_al_(x0) @ pts_model.T).T + np.array([x0[3:6]]) - pts_target).ravel()\n",
    "print('Check residual function ( =0): ', np.linalg.norm(r_x_al(x_gt_al).astype('float')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0af0c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_newton_rvec_step(x):\n",
    "    x_al = np2var(x, typeOf=VariableExt)\n",
    "    dr_al = r_x_al(x_al)\n",
    "    dr_f = dr_al.astype('float')\n",
    "    J_al = build_J_ad(dr_al, x_al)\n",
    "    dx = np.linalg.inv(J_al.T @ J_al) @ J_al.T @ dr_f\n",
    "    return dx\n",
    "\n",
    "x0 = np.array([0.001, 0, 0, 0.0, 0.0, 0.0]) # converging to the solution in 5 iterations\n",
    "optimizer_framework(gauss_newton_rvec_step, x0, x_gt_al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2612048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "OperationCounter.reset()\n",
    "\n",
    "x0_al = np2var(x0, typeOf=VariableExt)\n",
    "dr_al = r_x_al(x0_al)\n",
    "J_al = build_J_ad(dr_al, x0_al)\n",
    "\n",
    "print('To be sure that type is correct ( =True): ', type(dr_ad[0]) is VariableExt)\n",
    "print('Operation count: ', OperationCounter)\n",
    "# Euler angles were: {'add': 154, 'mul': 136, 'neg': 3, 'sin': 6, 'cos': 6}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9088598a",
   "metadata": {},
   "source": [
    "TODO: rotation matrix unknowns with lie algebra and automatic differentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9cadc9",
   "metadata": {},
   "source": [
    "# Timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3e6be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 5 -n 10\n",
    "cog_model = np.mean(pts_model, axis=0)\n",
    "cog_target = np.mean(pts_target, axis=0)\n",
    "pts_model_cog = pts_model - cog_model\n",
    "pts_target_cog = pts_target - cog_target\n",
    "C = pts_model_cog.T @ pts_target_cog\n",
    "[U, S, V] = np.linalg.svd(C) # this will be always the svd of a 3x3 matrix independently the number of points\n",
    "R_svd = V.T @ U.T\n",
    "t_svd = cog_target - R_svd @ cog_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09f9d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 5 -n 10\n",
    "x0 = np.array([0.001, 0, 0, 0.0, 0.0, 0.0])\n",
    "dx = np.inf \n",
    "iter_num = 0\n",
    "while np.linalg.norm(dx) > 1e-6 and iter_num < 100:\n",
    "    iter_num += 1\n",
    "    x0_al = np2var(x0, typeOf=VariableExt)\n",
    "    dr_al = r_x_al(x0_al)\n",
    "    J_al = build_J_ad(dr_al, x0_al)\n",
    "    dr_f = dr_al.astype('float')\n",
    "    #dx = np.linalg.inv(J_al.T @ J_al) @ J_al.T @ dr_f\n",
    "    dx = np.linalg.solve(J_al.T @ J_al, J_al.T @ dr_f)\n",
    "    x0 = x0 - dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a174efbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 5 -n 10\n",
    "x0 = np.array([0, 0, 0, 0, 0, 0])\n",
    "res = least_squares(r_x, x0, verbose=0, xtol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5a2c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
